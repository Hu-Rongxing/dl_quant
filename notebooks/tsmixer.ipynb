{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1b2d2f-1e32-4d49-9b85-22f903403681",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'set_jupyter.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dlquant-vxVcaLmo-py3.11\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:716\u001B[0m, in \u001B[0;36mExecutionMagics.run\u001B[1;34m(self, parameter_s, runner, file_finder)\u001B[0m\n\u001B[0;32m    715\u001B[0m     fpath \u001B[38;5;241m=\u001B[39m arg_lst[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 716\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[43mfile_finder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dlquant-vxVcaLmo-py3.11\\Lib\\site-packages\\IPython\\utils\\path.py:91\u001B[0m, in \u001B[0;36mget_py_filename\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m py_name\n\u001B[1;32m---> 91\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile `\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m` not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m name)\n",
      "\u001B[1;31mOSError\u001B[0m: File `'set_jupyter.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrun\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mset_jupyter.py\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dlquant-vxVcaLmo-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2478\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2479\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2480\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2483\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2484\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dlquant-vxVcaLmo-py3.11\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:727\u001B[0m, in \u001B[0;36mExecutionMagics.run\u001B[1;34m(self, parameter_s, runner, file_finder)\u001B[0m\n\u001B[0;32m    725\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnt\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m re\u001B[38;5;241m.\u001B[39mmatch(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m\"\u001B[39m,fpath):\n\u001B[0;32m    726\u001B[0m         warn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor Windows, use double quotes to wrap a filename: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124mun \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmypath\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmyfile.py\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 727\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    729\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fpath \u001B[38;5;129;01min\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mmeta_path:\n",
      "\u001B[1;31mException\u001B[0m: File `'set_jupyter.py'` not found."
     ]
    }
   ],
   "source": [
    "%run set_jupyter.py\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5230fe-9884-46e9-8b12-12146fcba502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from torch.nn.modules.loss import MSELoss, CrossEntropyLoss\n",
    "from pathlib import Path\n",
    "# 回调函数\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, precision_score \n",
    "\n",
    "from darts.models import TSMixerModel\n",
    "from darts.metrics import mape, mse\n",
    "\n",
    "# 自定义\n",
    "from config import TIMESERIES_LENGTH # 测试和验证数据长度设置\n",
    "from data_precessing.timeseries import prepare_timeseries_data  # 获取训练数据、验证数据和测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42290f-ada4-4bd3-9911-662b16da2b08",
   "metadata": {},
   "source": [
    "# 全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0511e-f17c-4876-b7d1-4b98610073d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path(\"logs/tsmixer_logs\").resolve() \n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0403868-b34d-415c-b79e-9b2dd93a6732",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d446e-dcf8-481a-8171-d3a5835fa68e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = prepare_timeseries_data('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f3ba0-685b-4a78-bac3-1f62ba9ec0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2fc55-c01e-4778-9160-1e0111d5757f",
   "metadata": {},
   "source": [
    "# 配置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531a3ad-9179-4630-9e8d-0c4380f03883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "\n",
    "class MAPELoss(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(MAPELoss, self).__init__()  \n",
    "\n",
    "    def forward(self, y_pred, y_true):  \n",
    "        # 确保真实值不为零，以避免除零错误  \n",
    "        epsilon = 1e-10  \n",
    "        mape = torch.mean(torch.abs((y_true - y_pred) / (y_true + epsilon))) * 100  \n",
    "        return mape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f6e49-b297-4055-b100-285e59a2445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练过程的损失值\n",
    "\n",
    "class LossLogger(Callback):\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    # will automatically be called at the end of each epoch\n",
    "    def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        self.train_loss.append(float(trainer.callback_metrics[\"train_loss\"]))\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        self.val_loss.append(float(trainer.callback_metrics[\"val_loss\"]))\n",
    "\n",
    "loss_logger = LossLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc4d1c-fa6a-43d8-a914-c1bc13e1e561",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class ModelParameters:  \n",
    "    \"\"\"模型参数\"\"\"  \n",
    "\n",
    "    def __init__(  \n",
    "            self,  \n",
    "            input_chunk_length=104, #13  \n",
    "            output_chunk_length=1,  \n",
    "            batch_size=64,  \n",
    "            full_training=True,\n",
    "            hidden_size=120,\n",
    "            ff_size=90,\n",
    "            num_blocks=7,\n",
    "            dropout=0.03\n",
    "    ):  \n",
    "        # 模型用于回溯的时间序列片段长度，即输入块长度  \n",
    "        self.input_chunk_length = input_chunk_length  # lookback window  \n",
    "        # 模型预测的时间序列长度，即输出块长度  \n",
    "        self.output_chunk_length = output_chunk_length  # forecast/lookahead window  \n",
    "        # 定义每个训练批次中的样本数量  \n",
    "        self.batch_size = batch_size  \n",
    "        # 随机数种子，用于结果复现  \n",
    "        self.random_state = 42  \n",
    "        # 工作目录，保存模型和输出的位置  \n",
    "        self.work_dir = work_dir  \n",
    "\n",
    "        # 第二个前馈层的隐藏层大小，决定模型容量  \n",
    "        self.hidden_size = hidden_size  \n",
    "        # 特征混合多层感知机（MLP）中第一前馈层的大小  \n",
    "        self.ff_size = ff_size  \n",
    "        # 模型中混合块的数量，包括首个块和所有后续块  \n",
    "        self.num_blocks = num_blocks  \n",
    "        # 在混合层中使用的激活函数名称。默认：”ReLU”  \n",
    "        # 可选项包括“ReLU”, “RReLU”, “PReLU”, “ELU”, “Softplus”, “Tanh”, “SELU”, “LeakyReLU”, “Sigmoid”, “GELU”  \n",
    "        self.activation = 'ReLU'  \n",
    "        # Dropout正则化率，用于防止过拟合  \n",
    "        self.dropout = dropout  \n",
    "        # 使用的LayerNorm变体类型。默认：“LayerNorm”。  \n",
    "        # 可选择“LayerNormNoBias”, “LayerNorm”, “TimeBatchNorm2d”。或者使用自定义的nn.Module。  \n",
    "        self.norm_type = 'LayerNorm'  \n",
    "        # 是否在进行其他层计算前进行归一化  \n",
    "        self.normalize_before = False  \n",
    "        # 是否使用静态协变量  \n",
    "        self.use_static_covariates = True  \n",
    "        # 是否使用可逆实例归一化RINorm来抵抗分布漂移，仅应用于目标序列特征，不适用于协变量  \n",
    "        self.use_reversible_instance_norm = False \n",
    "        # 优化器参数配置  \n",
    "        self.optimizer_kwargs = self.get_optimizer_kwargs()  \n",
    "        # PyTorch Lightning Trainer参数  \n",
    "        self.pl_trainer_kwargs = self.get_pl_trainer_kwargs(full_training)  \n",
    "        # 学习率调度器类，使用指数学习率调度器  \n",
    "        self.lr_scheduler_cls = torch.optim.lr_scheduler.ExponentialLR  \n",
    "        # 学习率调度器的参数配置  \n",
    "        self.lr_scheduler_kwargs = {\"gamma\": 0.999}  \n",
    "        # 概率预测使用的似然函数，默认为无  \n",
    "        self.likelihood = None  # use a `likelihood` for probabilistic forecasts  \n",
    "        # 确定性模型使用的损失函数，默认为均方误差  \n",
    "        loss_fn=\"binary_cross_entropy\"\n",
    "        # self.loss_fn = MSELoss()  # use a `loss_fn` for determinsitic model  \n",
    "        # self.loss_fn = MAPELoss()\n",
    "        # self.loss_fn = nn.L1Loss()\n",
    "        # 是否保存最佳模型状态的检查点  \n",
    "        self.save_checkpoints = True  # checkpoint to retrieve the best performing model state,  \n",
    "        # 是否覆盖同名模型的检查点  \n",
    "        self.force_reset = True  \n",
    "\n",
    "    # 获取PyTorch Lightning的训练参数  \n",
    "    def get_pl_trainer_kwargs(self, full_training):  \n",
    "        # 提前停止：若验证损失在10个epoch内没有减少1e-6则停止  \n",
    "        early_stopper = EarlyStopping(  \n",
    "            monitor=\"val_loss\",  \n",
    "            patience=10,  \n",
    "            min_delta=1e-6,  \n",
    "            mode=\"min\",  \n",
    "        )  \n",
    "\n",
    "        # PyTorch Lightning Trainer参数配置（可添加自定义回调）  \n",
    "        if full_training:  \n",
    "            limit_train_batches = None  \n",
    "            limit_val_batches = None  \n",
    "            max_epochs = 800  \n",
    "            batch_size = 64  \n",
    "        else:  \n",
    "            limit_train_batches = 20  \n",
    "            limit_val_batches = 10  \n",
    "            max_epochs = 40  \n",
    "            batch_size = 64  \n",
    "\n",
    "        # 仅显示训练和预测进度条  \n",
    "        progress_bar = TFMProgressBar(  \n",
    "            enable_sanity_check_bar=False, enable_validation_bar=False  \n",
    "        )  \n",
    "\n",
    "        pl_trainer_kwargs = {  \n",
    "            \"gradient_clip_val\": 1,  # 梯度剪裁，通过限制梯度的范围来稳定训练过程  \n",
    "            \"max_epochs\": max_epochs,  \n",
    "            \"limit_train_batches\": limit_train_batches,  \n",
    "            \"limit_val_batches\": limit_val_batches,  \n",
    "            \"accelerator\": \"auto\",  \n",
    "            \"callbacks\": [early_stopper, progress_bar, loss_logger],  \n",
    "        }  \n",
    "\n",
    "        return pl_trainer_kwargs  \n",
    "\n",
    "    # 获取优化器的参数配置  \n",
    "    def get_optimizer_kwargs(self):  \n",
    "        # 优化器配置，默认使用Adam  \n",
    "        optimizer_kwargs = {  \n",
    "            \"lr\": 1e-4,  \n",
    "            # \"optimizer_cls\": torch.optim.Adam  \n",
    "        }  \n",
    "        return optimizer_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd94b0d-131e-48cc-b57e-1b9bff63bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(ModelParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeceb70-df66-41ea-8972-51b0e46426a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSMixerModel(\n",
    "    **vars(ModelParameters()),\n",
    "    model_name=\"tsm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83226b3e-4da6-4d40-a67b-777117391593",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd57d4a-6dd8-4280-8aa1-cf7180c96035",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    # 训练集\n",
    "    series=data['train'],\n",
    "    past_covariates=data['past_covariates'],\n",
    "    future_covariates=data['future_covariates'],\n",
    "    # 验证集\n",
    "    val_series=data['val'],\n",
    "    val_past_covariates=data['past_covariates'],\n",
    "    val_future_covariates=data['future_covariates'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f201e24-ca4c-412b-9ed1-2dedac71f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_logger.train_loss, label='训练损失', color='red')\n",
    "plt.plot(loss_logger.val_loss, label='验证损失', color='blue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ee160-4779-4ba5-a6dc-a8a9d0b53032",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413dbe4-f2e6-46d4-975b-a6e1a9da0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(model_name='tsm', work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab783cb-33b2-4af6-be01-313cd3397412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will predict the next `pred_steps` points after the end of `pred_input`\n",
    "pred_steps = TIMESERIES_LENGTH[\"test_length\"]\n",
    "pred_input = data[\"test\"][:-pred_steps]\n",
    "\n",
    "pred_series = model.predict(n=pred_steps, series=pred_input)\n",
    "\n",
    "# 对预测结果进行二值化和展平 \n",
    "true_labels = data[\"test\"][-pred_steps:].values()  \n",
    "true_labels = true_labels.astype(int).flatten()  # Flatten to 1D   \n",
    "binary_predictions = pred_series.values() > 0.5  \n",
    "binary_predictions = binary_predictions.astype(int).flatten()  \n",
    "\n",
    "# 计算精确率  \n",
    "precision = precision_score(true_labels, binary_predictions)  \n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3215f-902b-4aba-bd6f-08b206631e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stock in enumerate(data[\"test\"].columns[:3]):\n",
    "    data[\"test\"][-pred_steps:].data_array().sel(component=stock).plot(label=f\"{stock}_实际数据\")\n",
    "    pred_series.data_array().sel(component=stock).plot(label=f\"{stock}_预测结果\")\n",
    "    # data['test'].slice_intersect(hfc).data_array().sel(component=stock).plot(label=f\"{stock}_实际数据\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ea29a-416f-43ee-b891-44821d981abf",
   "metadata": {},
   "source": [
    "# 超参调优"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337cc99-3f2b-4b82-9462-834a41390c71",
   "metadata": {},
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eabc51-29ba-4adf-81dd-ada3846eb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna  \n",
    "# import torch  \n",
    "# from torch.nn import MSELoss  \n",
    "from pytorch_lightning import Trainer, loggers as pl_loggers  \n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint  \n",
    "from sklearn.metrics import mean_squared_error  \n",
    "# from darts import TimeSeries  \n",
    "# from darts.models import TSMixerModel  \n",
    "# from darts.utils.callbacks import TFMProgressBar  \n",
    "\n",
    "from config import TIMESERIES_LENGTH\n",
    "\n",
    "# 假设 train, val, past_cov_ts 和 future_cov_ts 四个时间序列已经定义好  \n",
    "\n",
    "\n",
    "def objective(trial):  \n",
    "    input_chunk_length = trial.suggest_int(\"input_chunk_length\", 5, 128)  \n",
    "    output_chunk_length = trial.suggest_int(\"output_chunk_length\", 1, 8)  \n",
    "    # batch_size = trial.suggest_int(\"batch_size\", 32, 64)  \n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 128) \n",
    "    ff_size  = trial.suggest_int(\"ff_size\", 32, 128) \n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)  \n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 29)     \n",
    "\n",
    "    params = ModelParameters(  \n",
    "        input_chunk_length=input_chunk_length,  \n",
    "        output_chunk_length=output_chunk_length,  \n",
    "        # batch_size=batch_size,  \n",
    "        hidden_size=hidden_size, \n",
    "        ff_size = ff_size,\n",
    "        num_blocks=num_blocks,  \n",
    "        dropout=dropout,  \n",
    "        full_training=False  \n",
    "    )  \n",
    "\n",
    "    logger = pl_loggers.TensorBoardLogger(\"/data/tb_logs\", name=\"TSMixerModel\")  \n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(  \n",
    "        monitor='val_loss',  \n",
    "        dirpath=f\"/tata/optuna/trial_{trial.number}_checkpoints\",  \n",
    "        filename='{epoch}-{val_loss:.2f}',  \n",
    "        save_top_k=1,  \n",
    "        mode='min'  \n",
    "    )  \n",
    "\n",
    "    trainer = Trainer(  \n",
    "        logger=logger,  \n",
    "        callbacks=[model_checkpoint, TFMProgressBar()],  \n",
    "        max_epochs=params.pl_trainer_kwargs['max_epochs'],  \n",
    "        limit_train_batches=params.pl_trainer_kwargs['limit_train_batches'],  \n",
    "        limit_val_batches=params.pl_trainer_kwargs['limit_val_batches'],  \n",
    "        accelerator=params.pl_trainer_kwargs['accelerator']  \n",
    "    )  \n",
    "\n",
    "    model = TSMixerModel(**vars(params), model_name=\"tsm\")  \n",
    "\n",
    "    # 训练模型  \n",
    "    model.fit( \n",
    "\n",
    "        series=data['train'],\n",
    "        past_covariates=data['past_covariates'],\n",
    "        future_covariates=data['future_covariates'],\n",
    "        # 验证集\n",
    "        val_series=data['val'],\n",
    "        val_past_covariates=data['past_covariates'],\n",
    "        val_future_covariates=data['future_covariates'],\n",
    "          \n",
    "        verbose=True,  \n",
    "        trainer=trainer  # Now use the trainer  \n",
    "    )  \n",
    "\n",
    "    best_model_path = model_checkpoint.best_model_path  \n",
    "    trial.set_user_attr('best_model_path', best_model_path)  \n",
    "\n",
    "    # we will predict the next `pred_steps` points after the end of `pred_input`\n",
    "    pred_steps = TIMESERIES_LENGTH[\"test_length\"]\n",
    "    pred_input = data[\"test\"][:-pred_steps]\n",
    "    \n",
    "    pred_series = model.predict(n=pred_steps, series=pred_input)\n",
    "    \n",
    "    # 对预测结果进行二值化和展平 \n",
    "    true_labels = data[\"test\"][-pred_steps:].values()  \n",
    "    true_labels = true_labels.astype(int).flatten()  # Flatten to 1D   \n",
    "    binary_predictions = pred_series.values() > 0.5  \n",
    "    binary_predictions = binary_predictions.astype(int).flatten()  \n",
    "    \n",
    "    # 计算精确率  \n",
    "    precision = precision_score(true_labels, binary_predictions)  \n",
    "\n",
    "    return -precision \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261b1fc-80d0-4af6-9289-d89f7a04f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name='tsmixer',   # 变化\n",
    "    direction=\"minimize\",  \n",
    "    storage=\"sqlite:///data/optuna/assoptuna_study.db\",  \n",
    "    load_if_exists=True  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25246307-887c-406e-9ff4-4a5f29abbca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100, callbacks=[])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d4809-df47-43f3-95e6-bcf1ef3d8eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best trial:\")  \n",
    "trial = study.best_trial  \n",
    "print(\"  Value: \", trial.value)  \n",
    "print(\"  Params: \")  \n",
    "for key, value in trial.params.items():  \n",
    "    print(f\"    {key}: {value}\")  \n",
    "\n",
    "best_model_path = trial.user_attrs['best_model_path']  \n",
    "print(f\"Best model path: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c288c7-08de-41fe-af34-a430e53d1097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ec9d4-add1-4079-9b43-fdc0187dbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80e1c4-1e12-44fe-a1bc-488622506722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
